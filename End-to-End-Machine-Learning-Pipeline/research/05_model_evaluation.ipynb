{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP2YLnT-kEls"
      },
      "source": [
        "* project ç›®éŒ„ç‚º `End-to-End-Machine-Learning-Pipeline`ï¼Œä»¥ä¸‹è·¯å¾‘å‡ä»¥æ­¤ç‚º æ ¹ç›®éŒ„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mdN1QKMkElw"
      },
      "source": [
        "* `src/mlProject/constants/__init__.py` ä¸‹å®šç¾©äº†\n",
        "\n",
        "\t```python\n",
        "\tCONFIG_FILE_PATH\n",
        "\tPARAMS_FILE_PATH\n",
        "\tSCHEMA_FILE_PATH\n",
        "\t```\n",
        "\n",
        "* `src/mlProject/constants/__init__.py` è¦å…ˆå®Œæˆ (é‡å° 5. Update the configuration manager )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tj8x3BekElw"
      },
      "source": [
        "# è‡ªè¡Œå¯¦ä½œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN-kN1jmkElx",
        "outputId": "20236b33-c301-41e2-9d11-f9ab4a7d9095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLOps-Foundation'...\n",
            "remote: Enumerating objects: 444, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 444 (delta 70), reused 0 (delta 0), pack-reused 330 (from 1)\u001b[K\n",
            "Receiving objects: 100% (444/444), 3.12 MiB | 15.81 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/henrykohl/MLOps-Foundation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVlxS5fNkEly",
        "outputId": "bc01a0ca-2d42-4217-dd9d-bb02a4fd4866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ğŸ“¦ Installing...\n",
            "ğŸ“Œ Adjusting configuration...\n",
            "ğŸ©¹ Patching environment...\n",
            "â² Done in 0:00:11\n",
            "ğŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install() # expect a kernel restart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoR0rEASkEly"
      },
      "outputs": [],
      "source": [
        "!conda create -n mlproj python=3.8 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVfz5LVskEly",
        "outputId": "5dd64f21-9e8f-41a9-9d8d-097f951b5a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MLOps-Foundation/End-to-End-Machine-Learning-Pipeline\n"
          ]
        }
      ],
      "source": [
        "%cd MLOps-Foundation/End-to-End-Machine-Learning-Pipeline/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qZtzsPqjkElz",
        "outputId": "03053220-f931-402d-f7d6-32a082fb8f6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/MLOps-Foundation/End-to-End-Machine-Learning-Pipeline'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIU-rSwEkElz"
      },
      "outputs": [],
      "source": [
        "!source activate mlproj; pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dJyWjqVkEl0"
      },
      "source": [
        "* colab æ“ä½œæ™‚ï¼Œä¾åº\n",
        "  - å°‡ `01_data_ingestion.ipynb` ä¸­ï¼Œè‡ªè¡Œå¯¦ä½œçš„åŸ·è¡Œéƒ¨åˆ†è¤‡è£½éä¾†ï¼ŒåŸ·è¡Œä¸€æ¬¡ã€‚\n",
        "  - å°‡ `02_data_validation.ipynb` ä¸­ï¼Œè‡ªè¡Œå¯¦ä½œçš„åŸ·è¡Œéƒ¨åˆ†è¤‡è£½éä¾†ï¼ŒåŸ·è¡Œä¸€æ¬¡ã€‚\n",
        "  - å°‡ `03_data_transformation.ipynb` ä¸­ï¼Œè‡ªè¡Œå¯¦ä½œçš„åŸ·è¡Œéƒ¨åˆ†è¤‡è£½éä¾†ï¼ŒåŸ·è¡Œä¸€æ¬¡ã€‚\n",
        "  - å°‡ `04_model_trainer.ipynb` ä¸­ï¼Œè‡ªè¡Œå¯¦ä½œçš„åŸ·è¡Œéƒ¨åˆ†è¤‡è£½éä¾†ï¼ŒåŸ·è¡Œä¸€æ¬¡ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jZrUDKxHkEl0",
        "outputId": "59377c8e-82c8-4a20-9415-dd6335b8f1d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-17 11:12:12,107: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-17 11:12:12,110: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-17 11:12:12,113: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-17 11:12:12,113: INFO: common: created directory at: artifacts]\n",
            "[2025-12-17 11:12:12,113: INFO: common: created directory at: artifacts/data_ingestion]\n",
            "[2025-12-17 11:12:12,450: INFO: <stdin>: artifacts/data_ingestion/data.zip download! with following info: \n",
            "Connection: close\n",
            "Content-Length: 26176\n",
            "Cache-Control: max-age=300\n",
            "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
            "Content-Type: application/zip\n",
            "ETag: \"f751ec0917e15a3dc07c3094a49fb99713109dd8a9f29150bb5d187ec17facdf\"\n",
            "Strict-Transport-Security: max-age=31536000\n",
            "X-Content-Type-Options: nosniff\n",
            "X-Frame-Options: deny\n",
            "X-XSS-Protection: 1; mode=block\n",
            "X-GitHub-Request-Id: CC08:1815AD:43CC31:5380F2:6942900C\n",
            "Accept-Ranges: bytes\n",
            "Date: Wed, 17 Dec 2025 11:12:12 GMT\n",
            "Via: 1.1 varnish\n",
            "X-Served-By: cache-iad-kjyo7100167-IAD\n",
            "X-Cache: MISS\n",
            "X-Cache-Hits: 0\n",
            "X-Timer: S1765969932.370757,VS0,VE65\n",
            "Vary: Authorization,Accept-Encoding\n",
            "Access-Control-Allow-Origin: *\n",
            "Cross-Origin-Resource-Policy: cross-origin\n",
            "X-Fastly-Request-ID: abb928cbeb32f130bd620a5086d0eefc7b7a8a7f\n",
            "Expires: Wed, 17 Dec 2025 11:17:12 GMT\n",
            "Source-Age: 0\n",
            "\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "## 01_data_ingestion.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AeL2cuWE8ZSW",
        "outputId": "79a1ea57-8f3e-44ef-f621-5253bf0af65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-17 11:13:01,151: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-17 11:13:01,152: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-17 11:13:01,154: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-17 11:13:01,154: INFO: common: created directory at: artifacts]\n",
            "[2025-12-17 11:13:01,154: INFO: common: created directory at: artifacts/data_validation]\n"
          ]
        }
      ],
      "source": [
        "## 02_data_validation.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FTupQ9Te8ZEJ",
        "outputId": "749fb8b4-dbc2-4125-bf3b-0590f1c1ed43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-17 11:13:43,569: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-17 11:13:43,570: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-17 11:13:43,572: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-17 11:13:43,572: INFO: common: created directory at: artifacts]\n",
            "[2025-12-17 11:13:43,572: INFO: common: created directory at: artifacts/data_transformation]\n",
            "[2025-12-17 11:13:43,603: INFO: <stdin>: Splited data into training and test sets]\n",
            "[2025-12-17 11:13:43,603: INFO: <stdin>: (1199, 12)]\n",
            "[2025-12-17 11:13:43,603: INFO: <stdin>: (400, 12)]\n",
            "(1199, 12)\n",
            "(400, 12)\n"
          ]
        }
      ],
      "source": [
        "## 03_data_transformation.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sVeiMMBo8Yz4",
        "outputId": "16688941-a9ba-4db7-f141-ccbd8c502ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-17 11:14:52,457: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-17 11:14:52,458: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-17 11:14:52,460: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-17 11:14:52,461: INFO: common: created directory at: artifacts]\n",
            "[2025-12-17 11:14:52,461: INFO: common: created directory at: artifacts/model_trainer]\n"
          ]
        }
      ],
      "source": [
        "## 04_model_trainer.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY9oG-T38Zp8",
        "outputId": "9729d48d-e0bb-4af6-e825-287936cdcb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-12-19 12:02:09,300: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-19 12:02:09,302: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-19 12:02:09,305: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-19 12:02:09,306: INFO: common: created directory at: artifacts]\n",
            "[2025-12-19 12:02:09,306: INFO: common: created directory at: artifacts/model_evaluation]\n",
            "[2025-12-19 12:02:09,444: INFO: common: json file saved at: artifacts/model_evaluation/metrics.json]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate mlproj\n",
        "\n",
        "python\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ModelEvaluationConfig:\n",
        "    root_dir: Path          ## å®šç¾©åœ¨ config.yaml (model_evaluation)\n",
        "    test_data_path: Path    ## å®šç¾©åœ¨ config.yaml (model_evaluation)\n",
        "    model_path: Path        ## å®šç¾©åœ¨ config.yaml (model_evaluation)\n",
        "    all_params: dict        ## å®šç¾©åœ¨ params.yaml\n",
        "    metric_file_name: Path  ## å®šç¾©åœ¨ config.yaml (model_evaluation)\n",
        "    target_column: str      ## å®šç¾©åœ¨ schema.yaml\n",
        "\n",
        "\n",
        "from mlProject.constants import *\n",
        "from mlProject.utils.common import read_yaml, create_directories, save_json\n",
        "\n",
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "\t\t\t\tconfig_filepath = CONFIG_FILE_PATH,   ## è¼¸å‡º: PosixPath(\"config/config.yaml\")\n",
        "        params_filepath = PARAMS_FILE_PATH,   ## è¼¸å‡º: PosixPath(\"params.yaml\")\n",
        "        schema_filepath = SCHEMA_FILE_PATH):  ## è¼¸å‡º: PosixPath(\"schema.yaml\")\n",
        "\n",
        "        self.config = read_yaml(config_filepath) ## è¼¸å‡º: ConfigBox({...}); config.artifacts_root æ˜¯ str\n",
        "        self.params = read_yaml(params_filepath) ## è¼¸å‡º: ConfigBox({...})\n",
        "        self.schema = read_yaml(schema_filepath) ## è¼¸å‡º: ConfigBox({...})\n",
        "\n",
        "        create_directories([self.config.artifacts_root]) ## å»ºç«‹ç›®éŒ„ artifacts\n",
        "\n",
        "\n",
        "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
        "        config = self.config.model_evaluation   ## è¼¸å‡º: ConfigBox({...});\n",
        "        params = self.params.ElasticNet         ## è¼¸å‡º: ConfigBox({...});\n",
        "        schema =  self.schema.TARGET_COLUMN     ## è¼¸å‡º: ConfigBox({...});\n",
        "\n",
        "        create_directories([config.root_dir])   ## å»ºç›®éŒ„ artifacts/model_evaluation\n",
        "\n",
        "        model_evaluation_config = ModelEvaluationConfig(\n",
        "            root_dir=config.root_dir,                       ## artifacts/model_evaluation\n",
        "            test_data_path=config.test_data_path,           ## artifacts/data_transformation/test.csv\n",
        "            model_path = config.model_path,                 ## artifacts/model_trainer/model.joblib\n",
        "            all_params=params,                              ## params æ˜¯ ConfigBox é¡å‹\n",
        "            metric_file_name = config.metric_file_name,     ## artifacts/model_evaluation/metrics.json\n",
        "            target_column = schema.name                     ## quality\n",
        "\n",
        "        )\n",
        "\n",
        "        return model_evaluation_config\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from urllib.parse import urlparse\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "class ModelEvaluation:\n",
        "    def __init__(self, config: ModelEvaluationConfig):\n",
        "        self.config = config\n",
        "\n",
        "\n",
        "    def eval_metrics(self,actual, pred):          # actual é¡å‹: DataFrame, pred é¡å‹: ndarray\n",
        "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "        mae = mean_absolute_error(actual, pred)\n",
        "        r2 = r2_score(actual, pred)\n",
        "        return rmse, mae, r2\n",
        "\n",
        "\n",
        "\n",
        "    def save_results(self):\n",
        "\n",
        "        test_data = pd.read_csv(self.config.test_data_path) ## å¾ artifacts/data_transformation/test.csv\n",
        "        model = joblib.load(self.config.model_path)         ## å¾ artifacts/model_trainer/model.joblib\n",
        "\n",
        "        test_x = test_data.drop([self.config.target_column], axis=1)   ## test_data æ¨æ£„ quality æ¬„ (æ²’ç”¨åˆ°)\n",
        "        test_y = test_data[[self.config.target_column]]                ## test_data å–å¾— quality æ¬„ (æ²’ç”¨åˆ°)\n",
        "\n",
        "        predicted_qualities = model.predict(test_x)         ## è¼¸å…¥ DataFrame è¼¸å‡º ndarray\n",
        "\n",
        "        ## test_y é¡å‹: DataFrame, predicted_qualities é¡å‹: ndarray)\n",
        "        (rmse, mae, r2) = self.eval_metrics(test_y, predicted_qualities)\n",
        "\n",
        "        # Saving metrics as local\n",
        "        scores = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}                    ## è¼¸å…¥ (float, float, float)\n",
        "        save_json(path=Path(self.config.metric_file_name), data=scores)  ## åˆ° artifacts/model_evaluation/metrics.json\n",
        "\n",
        "\n",
        "try:\n",
        "    config = ConfigurationManager()                                  ## ä¾‹åŒ–configurationï¼Œå»ºç«‹ä¸»ç›®éŒ„\n",
        "    model_evaluation_config = config.get_model_evaluation_config()   ## åŸ·è¡Œconfigurationï¼Œå»ºç«‹æ¬¡ç›®éŒ„ï¼Œä¾‹åŒ–entity\n",
        "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config) ## ä¾‹åŒ– component\n",
        "    model_evaluation_config.save_results()                           ## åŸ·è¡Œ componentï¼Œ\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM3KwmLpkEl0"
      },
      "source": [
        "# Lecture Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNQZSABBkEl0",
        "outputId": "9a492f75-e1c2-4c44-c849-58d08850d67e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Bappy\\\\Live Sessions\\\\Euron\\\\MLOPs Masters Batch\\\\End-to-End-Machine-Learning-Pipeline'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"../\")\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi_7jUj6kEl1"
      },
      "source": [
        "## 4. Update the entity\n",
        "* project å°æ‡‰ `src/mlProject/entity/config_entity.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6DtyZzVkEl1"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ModelEvaluationConfig:\n",
        "    root_dir: Path          ## å®šç¾©åœ¨ config.yaml ä¹‹ model_evaluation; å¯¦éš›é¡å‹ str\n",
        "    test_data_path: Path    ## å®šç¾©åœ¨ config.yaml ä¹‹ model_evaluation; å¯¦éš›é¡å‹ str\n",
        "    model_path: Path        ## å®šç¾©åœ¨ config.yaml ä¹‹ model_evaluation; å¯¦éš›é¡å‹ str\n",
        "    all_params: dict        ## å®šç¾©åœ¨ params.yaml ä¹‹ ElasticNet; å¯¦éš›é¡å‹ ConfigBox\n",
        "    metric_file_name: Path  ## å®šç¾©åœ¨ config.yaml ä¹‹ model_evaluation; å¯¦éš›é¡å‹ str\n",
        "    target_column: str      ## å®šç¾©åœ¨ schema.yaml ä¹‹ TARGET_COLUMN;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meKsi1r9kEl1"
      },
      "source": [
        "## 5. Update the configuration manager\n",
        "* project å°æ‡‰ `src/mlProject/config/configuration.py`ç”¨åˆ°\n",
        "\t- '4. entity'ï¼š `src/mlProject/entity/config_entity.py` -- è¼¸å‡º ModelEvaluationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saNuQMpUkEl2"
      },
      "outputs": [],
      "source": [
        "from mlProject.constants import *\n",
        "from mlProject.utils.common import read_yaml, create_directories, save_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIsLoEYnkEl2"
      },
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "\t\t\t\tconfig_filepath = CONFIG_FILE_PATH,   ## è¼¸å‡º: PosixPath(\"config/config.yaml\")\n",
        "        params_filepath = PARAMS_FILE_PATH,   ## è¼¸å‡º: PosixPath(\"params.yaml\")\n",
        "        schema_filepath = SCHEMA_FILE_PATH):  ## è¼¸å‡º: PosixPath(\"schema.yaml\")\n",
        "\n",
        "        self.config = read_yaml(config_filepath) ## è¼¸å‡º: ConfigBox({...}); config.artifacts_root æ˜¯ str\n",
        "        self.params = read_yaml(params_filepath) ## è¼¸å‡º: ConfigBox({...})\n",
        "        self.schema = read_yaml(schema_filepath) ## è¼¸å‡º: ConfigBox({...})\n",
        "\n",
        "        create_directories([self.config.artifacts_root]) ## å»ºç«‹ç›®éŒ„ artifacts\n",
        "\n",
        "\n",
        "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
        "        config = self.config.model_evaluation   ## è¼¸å‡º: ConfigBox({...});\n",
        "        params = self.params.ElasticNet         ## è¼¸å‡º: ConfigBox({...});\n",
        "        schema =  self.schema.TARGET_COLUMN     ## è¼¸å‡º: ConfigBox({...});\n",
        "\n",
        "        create_directories([config.root_dir])   ## å»ºç›®éŒ„ artifacts/model_evaluation\n",
        "\n",
        "        model_evaluation_config = ModelEvaluationConfig(\n",
        "            root_dir=config.root_dir,                       ## 'artifacts/model_evaluation'\n",
        "            test_data_path=config.test_data_path,           ## 'artifacts/data_transformation/test.csv'\n",
        "            model_path = config.model_path,                 ## 'artifacts/model_trainer/model.joblib'\n",
        "            all_params=params,                              ## ConfigBox({'alpha': 0.2, ...})\n",
        "            metric_file_name = config.metric_file_name,     ## 'artifacts/model_evaluation/metrics.json'\n",
        "            target_column = schema.name                     ## 'quality'\n",
        "\n",
        "        )\n",
        "\n",
        "        return model_evaluation_config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52SV3XtgkEl2"
      },
      "source": [
        "## 6. Update the components\n",
        "* project å°æ‡‰ `src/mlProject/components/model_evaluation.py` ç”¨åˆ°\n",
        "\t- '4. entity'ï¼š `src/mlProject/entity/config_entity.py` -- è¼¸å…¥ ModelEvaluationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU49K3M6kEl2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from urllib.parse import urlparse\n",
        "import numpy as np\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v449R-IUkEl2"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluation:\n",
        "    def __init__(self, config: ModelEvaluationConfig):\n",
        "        self.config = config\n",
        "\n",
        "\n",
        "    def eval_metrics(self,actual, pred):                 # actual é¡å‹: Series, pred é¡å‹: Series\n",
        "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "        mae = mean_absolute_error(actual, pred)\n",
        "        r2 = r2_score(actual, pred)\n",
        "        return rmse, mae, r2\n",
        "\n",
        "\n",
        "\n",
        "    def save_results(self):\n",
        "\n",
        "        test_data = pd.read_csv(self.config.test_data_path) ## å¾ artifacts/data_transformation/test.csv\n",
        "        model = joblib.load(self.config.model_path)         ## å¾ artifacts/model_trainer/model.joblib\n",
        "\n",
        "        test_x = test_data.drop([self.config.target_column], axis=1)   ## test_data æ¨æ£„ quality æ¬„ (æ²’ç”¨åˆ°)\n",
        "        test_y = test_data[[self.config.target_column]]                ## test_data å–å¾— quality æ¬„ (æ²’ç”¨åˆ°)\n",
        "\n",
        "        predicted_qualities = model.predict(test_x)         ## è¼¸å…¥ DataFrame è¼¸å‡º ndarray\n",
        "\n",
        "        ## test_y é¡å‹: DataFrame, predicted_qualities é¡å‹: ndarray)\n",
        "        (rmse, mae, r2) = self.eval_metrics(test_y, predicted_qualities)\n",
        "\n",
        "        # Saving metrics as local\n",
        "        scores = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}                    ## è¼¸å…¥ (float, float, float)\n",
        "        save_json(path=Path(self.config.metric_file_name), data=scores)  ## åˆ° artifacts/model_evaluation/metrics.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs-ur9V1kEl3"
      },
      "source": [
        "## 7. Update the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HqP4TA9KiVx"
      },
      "source": [
        "* project å°æ‡‰ `src/mlProject/pipeline/stage_05_model_evaluation` éœ€èª¿ç”¨\n",
        "    - '5. configuration': `src/mlProject/config/configuration.py` -- è¼¸å‡º ModelEvaluationConfig\n",
        "    - '6. components': `src/mlProject/components/model_evaluation.py` -- è¼¸å…¥ DModelEvaluationConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbkw5QqNHDSe"
      },
      "source": [
        "* å®Œæˆå¾Œï¼Œå»ºç«‹ `artifacts/model_evaluation` è³‡æ–™å¤¾å…§åŒ…å« 'metrics.json' ä¸€å€‹æª”æ¡ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK4e-ZeDkEl3",
        "outputId": "e2a3ca95-70b7-41ec-c941-5008164ebc21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-01-12 13:09:29,149: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
            "[2025-01-12 13:09:29,150: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-01-12 13:09:29,151: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-01-12 13:09:29,152: INFO: common: created directory at: artifacts]\n",
            "[2025-01-12 13:09:29,153: INFO: common: created directory at: artifacts/model_evaluation]\n",
            "[2025-01-12 13:09:29,189: INFO: common: json file saved at: artifacts\\model_evaluation\\metrics.json]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  config = ConfigurationManager()                                  ## ä¾‹åŒ–configurationï¼Œå»ºç«‹ä¸»ç›®éŒ„\n",
        "  model_evaluation_config = config.get_model_evaluation_config()   ## åŸ·è¡Œconfigurationï¼Œå»ºç«‹æ¬¡ç›®éŒ„ï¼Œä¾‹åŒ–entity\n",
        "  model_evaluation_config = ModelEvaluation(config=model_evaluation_config) ## ä¾‹åŒ– component\n",
        "  model_evaluation_config.save_results()                                    ## åŸ·è¡Œ componentï¼Œæ¸¬è©¦çµæœå­˜æˆ json æª”\n",
        "except Exception as e:\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4exMaotkEl3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlproj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}